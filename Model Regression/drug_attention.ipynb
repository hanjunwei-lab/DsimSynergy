{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import deepchem as dc\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from model import Drug_Molecular, Cell_Line, GO_Network, ATC_Network, CNN_Drug, CNN_GO, CNN_ATC, FCNN, Synergy\n",
    "from drug_util import GraphDataset, collate, drug_feature_extract\n",
    "from process_data import getData\n",
    "from utils import  metric, set_seed_all, SynergyDataset, get_MACCS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "drug_smiles_file = '../Data/TRAIN/drug_smiles.csv'\n",
    "drug_go_file = '../Data/TRAIN/drug_go.csv'\n",
    "drug_atc_file = '../Data/TRAIN/drug_atc.csv'\n",
    "\n",
    "drug_smiles = pd.read_csv(drug_smiles_file, sep=\",\", header=0)\n",
    "drug_data = pd.DataFrame()\n",
    "drug_smiles_fea = []\n",
    "\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "for tup in zip(drug_smiles['drugbank_id'], drug_smiles['smiles']):\n",
    "    mol = Chem.MolFromSmiles(tup[1])\n",
    "    mol_f = featurizer.featurize(mol)\n",
    "    drug_data[str(tup[0])] = [mol_f[0].get_atom_features(), mol_f[0].get_adjacency_list()]\n",
    "    drug_smiles_fea.append(get_MACCS(tup[1]))\n",
    "\n",
    "drug_num = len(drug_data.keys())\n",
    "d_map = dict(zip(drug_data.keys(), range(drug_num)))\n",
    "drug_feature = drug_feature_extract(drug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---model_build\n",
    "DM_dim = [75,512,256] # Drug_Molecular\n",
    "CL_dim = [len(cell_feature[1]),256] # Cell_Line\n",
    "GN_dim = [len(drug_smiles_fea[1]),512,256] # GO_Network\n",
    "AN_dim = [len(drug_smiles_fea[1]),512,256] # ATC_Network\n",
    "\n",
    "CD_dim = [512,256] #Drug_Molecular+Cell_Line\n",
    "CO_dim = [512,256] #GO_Network+Cell_Line\n",
    "CT_dim = [512,256] #ATC_Network+Cell_Line\n",
    "FN_dim = [(CD_dim[1] * 2 + CO_dim[1] * 2 + CT_dim[1]* 2 + CL_dim[1]),[1024,512,128]]\n",
    "\n",
    "# Initialize the full synergy prediction model\n",
    "model = Synergy(Drug_Molecular(dim_drug = DM_dim[0], hidden_dim = DM_dim[1], output_dim = DM_dim[2], heads=4),\n",
    "                Cell_Line(dim_cellline = CL_dim[0], hidden_dim = CL_dim[1]),\n",
    "                GO_Network(feature_dim = GN_dim[0], hidden_dim = GN_dim[1], output_dim = GN_dim[2]),\n",
    "                ATC_Network(feature_dim = AN_dim[0], hidden_dim = AN_dim[1], output_dim = AN_dim[2]),\n",
    "                CNN_Drug(embed_dim = CD_dim[0], hidden_dim = CD_dim[1]),\n",
    "                CNN_GO(embed_dim = CO_dim[0], hidden_dim = CO_dim[1]),\n",
    "                CNN_ATC(embed_dim = CT_dim[0], hidden_dim = CT_dim[1]),\n",
    "                FCNN(embed_dim = FN_dim[0], hidden_dim = FN_dim[1])\n",
    "                ).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('the_best_model.pth', map_location=torch.device(device)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drug_structure = model.Drug_Molecular\n",
    "drug_set = Data.DataLoader(dataset=GraphDataset(graphs_dict=drug_feature),\n",
    "                        collate_fn=collate, batch_size=len(drug_feature), shuffle=False)\n",
    "for i ,drug in enumerate(drug_set,0):\n",
    "    drug_embed, (attention_weights_1, attention_weights_2) = model_drug_structure(drug,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_multihead_attention_scores(edge_index, attention_weights, num_nodes):\n",
    "    from collections import defaultdict\n",
    "    # 初始化每个节点的注意力分数为 0\n",
    "    node_attention_scores = defaultdict(float)\n",
    "    \n",
    "    # 对多头注意力权重进行平均\n",
    "    attention_weights = attention_weights.mean(dim=1)  # 平均所有头的注意力权重 (num_edges,)\n",
    "    \n",
    "    for i in range(edge_index.size(1)):\n",
    "        src_node = edge_index[0, i].item()  # 边的起始节点\n",
    "        weight = attention_weights[i].item()  # 对应的注意力权重\n",
    "        node_attention_scores[src_node] += weight\n",
    "    \n",
    "    # 转换为张量\n",
    "    scores = [node_attention_scores[node] for node in range(num_nodes)]\n",
    "    return torch.tensor(scores, dtype=torch.float32)\n",
    "def get_drug_attention_scores(batch, node_attention_scores):\n",
    "    max_batch = batch.max().item() + 1\n",
    "    drug_attention_scores = []\n",
    "    \n",
    "    for drug_idx in range(max_batch):\n",
    "        mask = (batch == drug_idx)\n",
    "        drug_scores = node_attention_scores[mask]\n",
    "        drug_attention_scores.append(drug_scores)\n",
    "    \n",
    "    return drug_attention_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,drug in enumerate(drug_set,0):\n",
    "    drug = drug\n",
    "\n",
    "# 提取第一层的注意力权重\n",
    "edge_index = attention_weights_1[0]\n",
    "attention_weights = attention_weights_1[1]\n",
    "# 聚合注意力分数到节点\n",
    "num_nodes = drug.x.size(0)\n",
    "node_attention_scores = aggregate_multihead_attention_scores(drug.edge_index, attention_weights, num_nodes).to(device)\n",
    "# 分配注意力分数到每个药物\n",
    "drug_attention_scores = get_drug_attention_scores(drug.batch, node_attention_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drug_structure_with_attention(edge_index, attention_scores, title=\"Drug Structure with Attention\", save_path=None, vmin=None, vmax=None):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import Normalize\n",
    "    import numpy as np\n",
    "    # 构建 NetworkX 图\n",
    "    G = nx.Graph()\n",
    "    edges = edge_index.t().tolist()  # 转换为 Python 列表\n",
    "    G.add_edges_from(edges)\n",
    "    # 确保 attention_scores 是 NumPy 数组\n",
    "    if isinstance(attention_scores, torch.Tensor):\n",
    "        attention_scores = attention_scores.numpy()\n",
    "    # 获取图中所有节点\n",
    "    nodes = list(G.nodes())\n",
    "    # 确保 attention_scores 的长度与图中的节点数一致\n",
    "    if len(attention_scores) != len(nodes):\n",
    "        raise ValueError(\"The length of attention_scores must match the number of nodes in the graph.\")\n",
    "    # 使用全局 vmin/vmax 进行归一化\n",
    "    global_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    normalized_scores = global_norm(attention_scores)\n",
    "    node_sizes = normalized_scores * 500 + 200  # 调整节点大小范围\n",
    "    # 使用 kamada_kawai_layout 来减少节点重叠\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    # 绘制图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = plt.gca()\n",
    "    # 使用 ScalarMappable 创建颜色映射\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=global_norm)\n",
    "    sm.set_array([])\n",
    "    # 绘制节点和边\n",
    "    nx.draw_networkx(G, pos, node_size=node_sizes, node_color=normalized_scores, cmap=plt.cm.Reds, with_labels=False, ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', width=1.0, alpha=0.7)\n",
    "    # 标注每个节点的注意力值\n",
    "    labels = {node: f\"{attention_scores[i]:.2f}\" for i, node in enumerate(nodes)}\n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=8, font_color='black', ax=ax)\n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(sm, orientation='vertical', label='Attention Score', ax=ax)\n",
    "    # 设置标题和去掉坐标轴\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    # 如果提供了保存路径，则保存为 PDF\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1_attention = drug_attention_scores[1444].cpu()\n",
    "drug2_attention = drug_attention_scores[1462].cpu()\n",
    "# 拼接成一个数组，找出最大值和最小值\n",
    "combined_attention = torch.cat([drug1_attention, drug2_attention], dim=0)\n",
    "vmin = combined_attention.min().item()\n",
    "vmax = combined_attention.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个药物\n",
    "first_drug_edge_index = edge_index[:, (drug.batch[edge_index[0]] == 1444)]\n",
    "first_drug_attention_scores = drug_attention_scores[1444]\n",
    "plot_drug_structure_with_attention(\n",
    "    first_drug_edge_index.cpu(),\n",
    "    first_drug_attention_scores.cpu(),\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    save_path=\"DB11967_attention.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二个药物\n",
    "first_drug_edge_index = edge_index[:, (drug.batch[edge_index[0]] == 1462)]\n",
    "first_drug_attention_scores = drug_attention_scores[1462]\n",
    "plot_drug_structure_with_attention(\n",
    "    first_drug_edge_index.cpu(),\n",
    "    first_drug_attention_scores.cpu(),\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    save_path=\"DB12267_attention.pdf\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
